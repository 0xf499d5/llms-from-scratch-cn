{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0460763",
   "metadata": {},
   "source": [
    "# 在未标记的数据集上进行预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c9945b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "from previous_chapters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a872cbc",
   "metadata": {},
   "source": [
    "# 0. 模型配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69ca72ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10b2b0ef0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"ctx_len\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"with_bias\": False,\n",
    "    \"with_mask\": True\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e54b50",
   "metadata": {},
   "source": [
    "## 1. 生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eaffe2",
   "metadata": {},
   "source": [
    "实现两个辅助函数以双向转换token ids和tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a3bac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text: str, tokenizer: tiktoken.Encoding) -> torch.Tensor:\n",
    "    token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    token_ids = torch.tensor(token_ids).reshape(1, -1)\n",
    "    # token_ids = torch.Tensor(token_ids).unsqueeze(0)\n",
    "    return token_ids\n",
    "\n",
    "def token_ids_to_text(token_ids: torch.Tensor, tokenizer: tiktoken.Encoding) -> str:\n",
    "    token_ids = token_ids.reshape(-1).tolist()\n",
    "    text = tokenizer.decode(token_ids)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54c0a4",
   "metadata": {},
   "source": [
    "调用GPT2Small和generate_text_simple函数以生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ce4ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ids' shape: torch.Size([1, 4])\n",
      "input token ids: \n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "\n",
      "output ids' shape: torch.Size([1, 14])\n",
      "output_ids: \n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308,  3398, 13174, 43071]])\n",
      "output text: \n",
      "Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "model = GPT2Small(\n",
    "    vocab_size=model_config[\"vocab_size\"],\n",
    "    ctx_len=model_config[\"ctx_len\"],\n",
    "    emb_dim=model_config[\"emb_dim\"],\n",
    "    n_heads=model_config[\"n_heads\"],\n",
    "    n_layers=model_config[\"n_layers\"],\n",
    "    dropout_rate=model_config[\"dropout_rate\"],\n",
    "    with_bias=model_config[\"with_bias\"],\n",
    "    with_mask=model_config[\"with_mask\"]\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "input_ids = text_to_token_ids(start_context, tokenizer)\n",
    "print(f\"input ids' shape: {input_ids.shape}\")\n",
    "print(f\"input token ids: \\n{input_ids}\\n\")\n",
    "\n",
    "output_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    indices=input_ids,\n",
    "    max_new_tokens=10,\n",
    "    context_size=256\n",
    ")\n",
    "print(f\"output ids' shape: {output_ids.shape}\")\n",
    "print(f\"output_ids: \\n{output_ids}\")\n",
    "\n",
    "output_text = token_ids_to_text(output_ids, tokenizer)\n",
    "print(f\"output text: \\n{output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f2283",
   "metadata": {},
   "source": [
    "# 2. 计算文本生成的好坏：多分类交叉熵损失函数和困惑度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314f5f1",
   "metadata": {},
   "source": [
    "## 2.1 多分类交叉熵损失函数\n",
    "多分类交叉熵损失函数公式如下：\n",
    "$$\n",
    "L = \\frac{1}{N}\\sum_{i} L_i = - \\frac{1}{N}\\sum_{i} \\sum_{c=1}^My_{ic}\\log(p_{ic}) \\\\\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- M ——类别的数量\n",
    "- y_{ic} ——符号函数（ 0 或 1 ），如果样本 i 的真实类别等于 c 取 1 ，否则取 0\n",
    "- p_{ic} ——观测样本 i 属于类别 c 的预测概率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b19a89",
   "metadata": {},
   "source": [
    "PyTorch已经实现了一个`cross_entropy`函数，可以直接使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa4dac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n"
     ]
    }
   ],
   "source": [
    "# 先准备两个batch的输入张量：\n",
    "input_texts = [\n",
    "    \"every effort moves\",\n",
    "    \"I really like\"\n",
    "]\n",
    "input_ids = torch.cat([text_to_token_ids(text, tokenizer) for text in input_texts])\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21ec7f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3626,  6100,   345],\n",
      "        [ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "source": [
    "# 然后准备对应的两个目标输出张量：\n",
    "target_texts = [\n",
    "    \" effort moves you\",\n",
    "    \" really like chocolate\"\n",
    "]\n",
    "target_ids = torch.cat([text_to_token_ids(text, tokenizer) for text in target_texts])\n",
    "print(target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11463b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([2, 3, 50257])\n",
      "logits: tensor([[[ 0.1113, -0.1057, -0.3666,  ...,  0.2843, -0.8824,  0.1074],\n",
      "         [-0.6109, -0.5167, -0.7613,  ...,  0.5450, -1.0319, -0.2175],\n",
      "         [ 0.5707, -0.6459, -0.0701,  ...,  0.7419, -0.1806, -0.2217]],\n",
      "\n",
      "        [[-0.2968,  0.1949, -0.1649,  ..., -0.4867,  0.7218, -0.1714],\n",
      "         [-0.8375,  0.0612, -0.4641,  ...,  0.2327, -0.3889, -0.0770],\n",
      "         [ 0.5614,  0.6919,  0.8915,  ..., -0.9472,  1.2411, -0.2056]]])\n"
     ]
    }
   ],
   "source": [
    "# 使用模型计算预测概率：\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids)\n",
    "print(f\"logits shape: {logits.shape}\")\n",
    "print(f\"logits: {logits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bafa2845",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [2, 50257], got [2, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 调用entropy_loss函数计算交叉熵损失：\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m loss = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected target size [2, 50257], got [2, 3]"
     ]
    }
   ],
   "source": [
    "# 调用entropy_loss函数计算交叉熵损失：\n",
    "loss = torch.nn.functional.cross_entropy(logits, target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73a9cbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([6, 50257])\n",
      "targets shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# 如上所示，需要对logits和target_ids进行reshape操作，\n",
    "# logits: (batch_size, num_tokens, vocab_size) -> (num_tokens_total, vocab_size)\n",
    "# target_ids: (batch_size, num_tokens) -> (num_tokens_total,)\n",
    "logits = logits.reshape(-1, logits.shape[-1])\n",
    "targets = target_ids.reshape(-1)\n",
    "print(f\"logits shape: {logits.shape}\")\n",
    "print(f\"targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99937995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is: 10.793963432312012\n"
     ]
    }
   ],
   "source": [
    "# reshape之后再重新计算损失：\n",
    "loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "print(f\"loss is: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb898867",
   "metadata": {},
   "source": [
    "## 2.2 困惑度\n",
    "关于困惑度的在不同场合下的定义，可以参考：[困惑度(perplexity)的基本概念及多种模型下的计算（N-gram, 主题模型, 神经网络）](https://zhuanlan.zhihu.com/p/114432097)。\n",
    "\n",
    "我们在这里只需要简单地认为困惑度就是交叉熵损失的指数函数的计算结果即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ccc0160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity is: 48725.7734375\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(f\"perplexity is: {perplexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4518a",
   "metadata": {},
   "source": [
    "# 3. 划分训练集和验证集\n",
    "内容大纲：\n",
    "1. 加载原始的文本数据集\n",
    "2. 将原始的数据集划分为训练集和验证集\n",
    "3. 实现损失计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c419f2",
   "metadata": {},
   "source": [
    "## 3.1 加载原始的文本数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "011e276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "corpus_file_path = \"./the-verdict.txt\"\n",
    "with open(corpus_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d17ac70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total characters: 20479\n",
      "number of total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "num_total_chars = len(corpus)\n",
    "print(f\"number of total characters: {num_total_chars}\")\n",
    "\n",
    "num_total_tokens = len(tokenizer.encode(corpus))\n",
    "print(f\"number of total tokens: {num_total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0e612",
   "metadata": {},
   "source": [
    "## 3.2 将原始的数据集划分为训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09bf8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9 ## 训练集占总数据量的比例\n",
    "split_idx = int(train_ratio * len(corpus))\n",
    "train_set = corpus[:split_idx]\n",
    "valid_set = corpus[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4263106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert round(len(train_set) / len(valid_set)) == 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be8a9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# 加载训练集：\n",
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_set,\n",
    "    batch_size=2,\n",
    "    max_length=model_config[\"ctx_len\"],\n",
    "    stride=model_config[\"ctx_len\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 加载验证集：\n",
    "valid_loader = create_dataloader_v1(\n",
    "    txt=valid_set,\n",
    "    batch_size=2,\n",
    "    max_length=model_config[\"ctx_len\"],\n",
    "    stride=model_config[\"ctx_len\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9202b660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "valid set loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 检查数据是否能够正确加载：\n",
    "print(\"train set loader:\")\n",
    "for x, t in train_loader:\n",
    "    print(x.shape, t.shape)\n",
    "\n",
    "print(\"valid set loader:\")\n",
    "for x, t in valid_loader:\n",
    "    print(x.shape, t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef1352",
   "metadata": {},
   "source": [
    "## 3.3 实现损失计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88fb9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(x_batch, t_batch, model: torch.nn.Module, device: torch.device):\n",
    "    x_batch = x_batch.to(device)\n",
    "    t_batch = t_batch.to(device)\n",
    "\n",
    "    logits = model(x_batch)\n",
    "    logits = logits.reshape(-1, logits.shape[-1])\n",
    "    targets = t_batch.reshape(-1)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_epoch(dataloader, model, device, num_batches: int = None):\n",
    "    loss_sum = 0.\n",
    "    if num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(len(dataloader), num_batches)\n",
    "    \n",
    "    for i, (x_batch, t_batch) in enumerate(dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = calc_loss_batch(x_batch, t_batch, model, device)\n",
    "        loss_sum += loss\n",
    "    loss_mean = loss_sum / num_batches\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40ef21e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.98758316040039\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(type(device))\n",
    "model.to(device)\n",
    "\n",
    "# 训练模型\n",
    "train_loss = calc_loss_epoch(train_loader, model, device)\n",
    "print(f\"Train loss: {train_loss}\")\n",
    "\n",
    "# 验证模型\n",
    "valid_loss = calc_loss_epoch(valid_loader, model, device)\n",
    "print(f\"Validation loss: {valid_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8bb09f",
   "metadata": {},
   "source": [
    "# 4. 训练模型\n",
    "内容大纲：\n",
    "1. 实现模型验证\n",
    "2. 生成文本\n",
    "3. 实现模型训练\n",
    "4. 可视化收敛情况"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5be8b",
   "metadata": {},
   "source": [
    "## 4.1 实现模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3ebf874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, train_loader, valid_loader, device, num_batches):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_epoch(train_loader, model, device, num_batches)\n",
    "        valid_loss = calc_loss_epoch(valid_loader, model, device, num_batches)\n",
    "    model.train()\n",
    "    return train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40ffb3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 10.991314888000488, valid_loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_losss = evaluate(model, train_loader, valid_loader, device, num_batches=2)\n",
    "print(f\"train_loss: {train_loss}, valid_loss: {valid_losss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d2fd4",
   "metadata": {},
   "source": [
    "## 4.2 在经过一个epoch的训练之后生成预测文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ae58207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, device, start_context) -> str:\n",
    "    model.eval()\n",
    "    ctx_size = model.tok_emb.weight.shape[0]\n",
    "    input_ids = text_to_token_ids(start_context, tokenizer)\n",
    "    with torch.no_grad():\n",
    "        output_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            indices=input_ids,\n",
    "            max_new_tokens=50,\n",
    "            context_size=ctx_size\n",
    "        )\n",
    "        predicted_text = token_ids_to_text(output_ids, tokenizer)\n",
    "        print(predicted_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdae58a",
   "metadata": {},
   "source": [
    "## 4.3 实现模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b00e50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    num_batches,\n",
    "    start_context\n",
    "):\n",
    "    train_losses = []  # 训练周期内所有的损失值\n",
    "    valid_losses = []  # 训练周期内所有的损失值\n",
    "    total_tokens_seen = []  # 训练周期内总共处理的token数\n",
    "    tokens_seen = 0  # 当前epoch处理的token数\n",
    "    global_step = 0  # 当前经过训练的样本数\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, valid_loss = evaluate(\n",
    "                    model,\n",
    "                    train_loader,\n",
    "                    valid_loader,\n",
    "                    device,\n",
    "                    num_batches\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                valid_losses.append(valid_loss)\n",
    "                total_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch: {e}, Step: {global_step}, Train Loss: {train_loss:.3f}, Valid Loss: {valid_loss:.3f}\")\n",
    "        generate_text(model, tokenizer, device, start_context)\n",
    "    return train_losses, valid_losses, total_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "307d66ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 5, Train Loss: 9.272, Valid Loss: 9.539\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Epoch: 1, Step: 10, Train Loss: 8.781, Valid Loss: 8.975\n",
      "Epoch: 1, Step: 15, Train Loss: 8.294, Valid Loss: 8.497\n",
      "Every effort moves you, the, the the the the the the the, the the, the, the, the the, the the,, the the the, the, the the the, the the the the the, the, the the, the, the the\n",
      "Epoch: 2, Step: 20, Train Loss: 7.768, Valid Loss: 8.063\n",
      "Epoch: 2, Step: 25, Train Loss: 7.184, Valid Loss: 7.656\n",
      "Every effort moves you, the, the, the, the, the, the.                                     \n",
      "Epoch: 3, Step: 30, Train Loss: 6.738, Valid Loss: 7.325\n",
      "Epoch: 3, Step: 35, Train Loss: 6.275, Valid Loss: 7.061\n",
      "Every effort moves you, and, and the the. \". \". \".   \", and the   \" \" I had the the the \". \" \".  \". \", I\n",
      "Epoch: 4, Step: 40, Train Loss: 5.885, Valid Loss: 6.908\n",
      "Epoch: 4, Step: 45, Train Loss: 5.445, Valid Loss: 6.645\n",
      "Every effort moves you, and I had the the of the of the the of the.                                    \n",
      "Epoch: 5, Step: 50, Train Loss: 5.093, Valid Loss: 6.580\n",
      "Every effort moves you.       \"I, I had the. \"I was I was his I was I was.               \"I had the, I was his\n",
      "Epoch: 6, Step: 55, Train Loss: 4.741, Valid Loss: 6.462\n",
      "Epoch: 6, Step: 60, Train Loss: 4.440, Valid Loss: 6.375\n",
      "Every effort moves you know the, and in the of the picture to the of the.             \", I, I was, and, and he was his, the, and--I, I was his\n",
      "Epoch: 7, Step: 65, Train Loss: 3.973, Valid Loss: 6.364\n",
      "Epoch: 7, Step: 70, Train Loss: 3.766, Valid Loss: 6.354\n",
      "Every effort moves you know it was his pictures--I had been to the fact of the. \"I was--I had the, I had been to the the, and I had been the.   \"I, and--and, and in his\n",
      "Epoch: 8, Step: 75, Train Loss: 3.490, Valid Loss: 6.258\n",
      "Epoch: 8, Step: 80, Train Loss: 3.018, Valid Loss: 6.252\n",
      "Every effort moves you know.    \"--I he was a a me. \"I was--I--and it's the that, in the he had the his pictures--I had been his he had been the--I had been the his\n",
      "Epoch: 9, Step: 85, Train Loss: 2.840, Valid Loss: 6.299\n",
      "Epoch: 9, Step: 90, Train Loss: 2.607, Valid Loss: 6.295\n",
      "Every effort moves you know. \"I was a he was--I had a little to have to have to work, and to me to have to see a little of his pictures--and I had been his painting, the donkey.      \n"
     ]
    }
   ],
   "source": [
    "# 好了，现在可以预训练大模型了：\n",
    "torch.manual_seed(123)\n",
    "model = GPT2Small(\n",
    "    vocab_size=model_config[\"vocab_size\"],\n",
    "    ctx_len=model_config[\"ctx_len\"],\n",
    "    emb_dim=model_config[\"emb_dim\"],\n",
    "    n_heads=model_config[\"n_heads\"],\n",
    "    n_layers=model_config[\"n_layers\"],\n",
    "    dropout_rate=model_config[\"dropout_rate\"],\n",
    "    with_bias=model_config[\"with_bias\"],\n",
    "    with_mask=model_config[\"with_mask\"]\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, valid_losses, total_tokens_seen = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    num_batches=5,\n",
    "    start_context=\"Every effort moves you\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d648865",
   "metadata": {},
   "source": [
    "## 4.4 可视化收敛情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "572e318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # 绘制随着训练进行（epoch值增大）训练集损失和验证集损失的变化情况\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "\n",
    "    # 创建第二个x轴用于显示可观察的tokens\n",
    "    ax2 = ax1.twiny()  # 创建一个共享相同y轴的第二个x轴\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 用于对齐刻度的不可见图表\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # 调整布局以节省空间\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58561a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, total_tokens_seen, train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ea2a8",
   "metadata": {},
   "source": [
    "# 5. 文本生成的多样性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd6a2108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n",
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n",
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n",
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n",
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n",
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n",
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n",
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n",
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n",
      "output text: Every effort moves you know.\n",
      "\"I was a he was--I had a little to have to have to work, and to me to\n"
     ]
    }
   ],
   "source": [
    "# 原有的文本生成策略是每次都会从词表中选择概率最大的那个token返回：\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "for _ in range(10):\n",
    "    output_ids = generate_text_simple(\n",
    "        model=model,\n",
    "        indices=text_to_token_ids(\"Every effort moves you\", tokenizer=tokenizer),\n",
    "        max_new_tokens=25,\n",
    "        context_size=model_config[\"ctx_len\"]\n",
    "    )\n",
    "    output_text = token_ids_to_text(output_ids, tokenizer=tokenizer)\n",
    "    print(f\"output text: {output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa7b91d",
   "metadata": {},
   "source": [
    "如上所述，我们可以看到，对同一个上下文，重复生成的预测文本都是一样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156ebaf",
   "metadata": {},
   "source": [
    "## 5.1 可放回的多项式分布抽样\n",
    "\n",
    "为了增加生成文本的多样性，我们可以使用`torch.multinomial`函数从多项式分布中进行放回抽样。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cba5a51",
   "metadata": {},
   "source": [
    "首先，我们构造一个只有9个单词的小型词汇表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8cad565",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inversed_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7447bbb3",
   "metadata": {},
   "source": [
    "现在，假设输入的文本是“Every effort moves you”，\n",
    "而模型返回的logits如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98f0e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a114de",
   "metadata": {},
   "source": [
    "这时候我们使用softmax函数将上述logits转换为概率分布，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5700326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next token: forward\n"
     ]
    }
   ],
   "source": [
    "probs = torch.softmax(logits, dim=0)\n",
    "next_token_id = torch.argmax(probs).item()\n",
    "next_token = inversed_vocab[next_token_id]\n",
    "print(f\"next token: {next_token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10feb63a",
   "metadata": {},
   "source": [
    "OK，这是之前的文本生成策略，现在，我们把`torch.argmax`改为`torch.multinomial`，以实现从概率分布中采样得到下一个token："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98500751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next token:  forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "print(\"next token: \", inversed_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5affb4",
   "metadata": {},
   "source": [
    "为了验证使用多项式分布采样来获取下一个token的随机性，我们可以使用`torch.bincount`方法来统计多次采样的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9943dbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer: 73\n",
      "every: 0\n",
      "effort: 0\n",
      "forward: 581\n",
      "inches: 2\n",
      "moves: 0\n",
      "pizza: 0\n",
      "toward: 344\n"
     ]
    }
   ],
   "source": [
    "# 采样1000次：\n",
    "samples = [torch.multinomial(probs, num_samples=1).item() for _ in range(1000)]\n",
    "token_freqs = torch.bincount(torch.tensor(samples))\n",
    "for i, f in enumerate(token_freqs):\n",
    "    t = inversed_vocab[i]\n",
    "    print(f\"{t}: {f.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050eb3ae",
   "metadata": {},
   "source": [
    "所以，我们可以不再使用`torch.argmax`来避免每次生成同样的tokens，而是使用`torch.multinomial`来从概率分布中随机采样。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08191ccc",
   "metadata": {},
   "source": [
    "## 5.2 温度缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0d4a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ca024cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义三个温度缩放因子以作比较：\n",
    "temperatures = [1, 0.1, 5]\n",
    "\n",
    "# 计算经过上述缩放因子缩放的概率分布：\n",
    "scaled_probs = [softmax_with_temperature(logits, t) for t in temperatures]\n",
    "# print(f\"scaled probs: \\n{scaled_probs}\")\n",
    "# print(f\"logits shape: {logits.shape}\")\n",
    "# print(f\"scaled_probs' shape: {scaled_probs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6458d9",
   "metadata": {},
   "source": [
    "接着，我们画出三个缩放因子下的概率分布："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3501826d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, T in enumerate(temperatures):\n",
    "    # 条形图的绘制，ax.bar()函数里面的参数分别为条形的x轴位置、高度、宽度、图例标签\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probs[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c17a10",
   "metadata": {},
   "source": [
    "从上图可以看出，当缩放因子为1的时候，相当于没有进行缩放；而当缩放因子小于1的时候，会让这个概率分布变得更加集中；反之，当缩放因子大于1的时候，会让这个概率分布变得更加均匀。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c1db2",
   "metadata": {},
   "source": [
    "# 5.3 TopK采样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48218e19",
   "metadata": {},
   "source": [
    "为了能够使得生成文本更具多样性，并降低无异议句子的出现概率，我们可以降采样的下一个token限制在最有可能出现的K个候选token中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "327c68ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "topk = 3\n",
    "top_logits, top_pos = torch.topk(logits, topk)\n",
    "print(f\"top logits: {top_logits}\")\n",
    "print(f\"top positions: {top_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16caec13",
   "metadata": {},
   "source": [
    "接着，我们可以构造一个类似mask-attention那样的掩码矩阵，用来屏蔽不在K个候选token集合中的其他token："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "709d3782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "masked_logits = torch.where(\n",
    "    condition=logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")),  # 用来填充不在K个候选token对应的logits元素\n",
    "    other=logits,  # 其余元素保持不变\n",
    ")\n",
    "print(masked_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab78523",
   "metadata": {},
   "source": [
    "最后，继续使用softmax函数将masked_logits转换为概率分布："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59a37a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probs = torch.softmax(masked_logits, dim=0)\n",
    "print(topk_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f08e0",
   "metadata": {},
   "source": [
    "# 5.4 包含温度缩放以及TopK采样的文本生成策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c93da20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature, top_k=None):\n",
    "\n",
    "    # 循环与之前相同：获取logits，并仅关注最后一步。\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 使用top_k采样对logits值进行过滤\n",
    "        if top_k is not None:\n",
    "            # 仅保留top_k的值\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        # 使用温度缩放\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # 使用softmax函数得到概率\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # 从概率分布中采样\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # 否则和之前的generate_simple函数中的处理相同，使用argmax函数取得概率最大的token\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        # 和之前相同的序列拼接处理\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8decae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you in to Gisburn. It--because he had the by his! I was: \"I\n",
      "Output text:\n",
      " Every effort moves you know to my way that my, in the to the so with a. And it was his painting\n",
      "Output text:\n",
      " Every effort moves you in the's up that, Mrs. The with't\n",
      "\"I must up and that he was\n",
      "Output text:\n",
      " Every effort moves you of that, and-rooms, of the with the- with that one of her own--and\n",
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\".\n",
      "He he was with a and I felt of a and in him--\n",
      "Output text:\n",
      " Every effort moves you, it to to my, and he was--, it. Gisburn in him my work\n",
      "Output text:\n",
      " Every effort moves you, one of his pictures--, of a he't-hum, in him--as he was\n",
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\n",
      "\n",
      "I felt him--'s an of the me in an and in the fact\n",
      "Output text:\n",
      " Every effort moves you, he to to my dear his he had a his of the that in a flash it the--\n",
      "Output text:\n",
      " Every effort moves you, with him, and in one of the he had with the fact of--because he was no\n"
     ]
    }
   ],
   "source": [
    "# 测试一波使用心得生成策略的文本生成函数：\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for _ in range(10):\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "        max_new_tokens=20,\n",
    "        context_size=model_config[\"ctx_len\"],\n",
    "        top_k=10,\n",
    "        temperature=1.5\n",
    "    )\n",
    "\n",
    "    print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4eb0ae",
   "metadata": {},
   "source": [
    "可以看到，每次生成的文本都已经不再是相同的了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9615581f",
   "metadata": {},
   "source": [
    "# 6. 使用`PyTorch`保存和加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed30d6",
   "metadata": {},
   "source": [
    "## 6.1 保存模型以及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22063e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    obj={\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict()\n",
    "    },\n",
    "    f=\"gpt2_small_and_adamw.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ffa8d",
   "metadata": {},
   "source": [
    "## 6.2 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6e0fdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Small(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (decoder): Sequential(\n",
       "    (0): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm()\n",
       "  (out): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"gpt2_small_and_adamw.pth\")\n",
    "\n",
    "model = GPT2Small(\n",
    "    vocab_size=model_config[\"vocab_size\"],\n",
    "    ctx_len=model_config[\"ctx_len\"],\n",
    "    emb_dim=model_config[\"emb_dim\"],\n",
    "    n_heads=model_config[\"n_heads\"],\n",
    "    n_layers=model_config[\"n_layers\"],\n",
    "    dropout_rate=model_config[\"dropout_rate\"],\n",
    "    with_bias=model_config[\"with_bias\"],\n",
    "    with_mask=model_config[\"with_mask\"]\n",
    ")\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34552f8f",
   "metadata": {},
   "source": [
    "# 7. 从OpenAI加载预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6159d2",
   "metadata": {},
   "source": [
    "## 7.1 下载预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b95618",
   "metadata": {},
   "source": [
    "在运行随书代码的时候我们已经下载过模型权重了，\n",
    "所以这时候并不需要重新下载，只需要重用之前的权重即可。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af069b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path: /Users/eassi/ws/py/llms-from-scratch-cn/Codes/ch05/01_main-chapter-code/gpt2/124M\n",
      "model path exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "models_dir = \"gpt2\"\n",
    "model_size = \"124M\"\n",
    "model_path = os.path.abspath(\n",
    "    os.path.join(\n",
    "        \"../\",\n",
    "        \"../\",\n",
    "        \"Codes\",\n",
    "        \"ch05\",\n",
    "        \"01_main-chapter-code\",\n",
    "        models_dir,\n",
    "        model_size\n",
    "    )\n",
    ")\n",
    "print(f\"model path: {model_path}\")\n",
    "print(f\"model path exists: {os.path.exists(model_path)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af57af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpt_download import load_gpt2_params_from_tf_ckpt\n",
    "\n",
    "tf_ckpt_path = tf.train.latest_checkpoint(model_path)\n",
    "hparams = json.load(open(os.path.join(model_path, \"hparams.json\")))\n",
    "params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a02b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(f\"settings: {hparams}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c89d842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"parameter dictionary keys: {params.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc6e6e",
   "metadata": {},
   "source": [
    "## 7.2 设置实例化GPT2Small模型所需的配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c38fb39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ctx_len': 1024,\n",
      " 'dropout_rate': 0.1,\n",
      " 'emb_dim': 768,\n",
      " 'n_heads': 12,\n",
      " 'n_layers': 12,\n",
      " 'vocab_size': 50257,\n",
      " 'with_bias': True,\n",
      " 'with_mask': True}\n"
     ]
    }
   ],
   "source": [
    "model_config = hparams.copy()\n",
    "\n",
    "# 先确认一下模型初始化的参数长什么样：\n",
    "# help(GPT2Small)\n",
    "\n",
    "model_config = {\n",
    "    \"vocab_size\": hparams[\"n_vocab\"],\n",
    "    \"ctx_len\": hparams[\"n_ctx\"],\n",
    "    \"emb_dim\": hparams[\"n_embd\"],\n",
    "    \"n_heads\": hparams[\"n_head\"],\n",
    "    \"n_layers\": hparams[\"n_layer\"],\n",
    "    \"dropout_rate\": 0.1, # todo: 需要再确认\n",
    "    \"with_bias\": True,\n",
    "    \"with_mask\": True\n",
    "}\n",
    "from pprint import pprint\n",
    "pprint(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a5a5f",
   "metadata": {},
   "source": [
    "## 7.3 加载模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b76e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt2, params):\n",
    "    # Weight tying\n",
    "    gpt2.pos_emb.weight = assign(gpt2.pos_emb.weight, params['wpe'])\n",
    "    gpt2.tok_emb.weight = assign(gpt2.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        wq, wk, wv = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt2.decoder[b].mha.wq.weight = assign(gpt2.decoder[b].mha.wq.weight, wq.T)\n",
    "        gpt2.decoder[b].mha.wk.weight = assign(gpt2.decoder[b].mha.wk.weight, wk.T)\n",
    "        gpt2.decoder[b].mha.wv.weight = assign(gpt2.decoder[b].mha.wv.weight, wv.T)\n",
    "    \n",
    "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt2.decoder[b].mha.wq.bias = assign(gpt2.decoder[b].mha.wq.bias, q_b)\n",
    "        gpt2.decoder[b].mha.wk.bias = assign(gpt2.decoder[b].mha.wk.bias, k_b)\n",
    "        gpt2.decoder[b].mha.wv.bias = assign(gpt2.decoder[b].mha.wv.bias, v_b)\n",
    "    \n",
    "        gpt2.decoder[b].mha.out_proj.weight = assign(gpt2.decoder[b].mha.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt2.decoder[b].mha.out_proj.bias = assign(gpt2.decoder[b].mha.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "    \n",
    "        gpt2.decoder[b].ffn.layers[0].weight = assign(gpt2.decoder[b].ffn.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt2.decoder[b].ffn.layers[0].bias = assign(gpt2.decoder[b].ffn.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt2.decoder[b].ffn.layers[2].weight = assign(gpt2.decoder[b].ffn.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt2.decoder[b].ffn.layers[2].bias = assign(gpt2.decoder[b].ffn.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "    \n",
    "        gpt2.decoder[b].norm1.scale = assign(gpt2.decoder[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt2.decoder[b].norm1.shift = assign(gpt2.decoder[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt2.decoder[b].norm2.scale = assign(gpt2.decoder[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt2.decoder[b].norm2.shift = assign(gpt2.decoder[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    \n",
    "        gpt2.norm.scale = assign(gpt2.norm.scale, params[\"g\"])\n",
    "        gpt2.norm.shift = assign(gpt2.norm.shift, params[\"b\"])\n",
    "        gpt2.out.weight = assign(gpt2.out.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1daaa5",
   "metadata": {},
   "source": [
    "OK，现在可以实例化模型并加载权重了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b40e9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Small(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (decoder): Sequential(\n",
       "    (0): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerDecoderOnly(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm()\n",
       "  (out): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2 = GPT2Small(\n",
    "    vocab_size=model_config[\"vocab_size\"],\n",
    "    ctx_len=model_config[\"ctx_len\"],\n",
    "    emb_dim=model_config[\"emb_dim\"],\n",
    "    n_heads=model_config[\"n_heads\"],\n",
    "    n_layers=model_config[\"n_layers\"],\n",
    "    dropout_rate=model_config[\"dropout_rate\"],\n",
    "    with_bias=model_config[\"with_bias\"],\n",
    "    with_mask=model_config[\"with_mask\"]\n",
    ")\n",
    "gpt2.eval()\n",
    "\n",
    "load_weights_into_gpt(gpt2, params)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b1a47",
   "metadata": {},
   "source": [
    "## 7.4 使用预训练好的模型生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be213f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text: \n",
      "Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "output_ids = generate(\n",
    "    model=gpt2,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=model_config[\"ctx_len\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "output_text = token_ids_to_text(output_ids, tokenizer)\n",
    "print(f\"output text: \\n{output_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
