{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45398736-7e89-4263-89c8-92153baff553",
   "metadata": {},
   "source": [
    "<font size=\"1\">\n",
    "Supplementary code for \"Build a Large Language Model From Scratch\": <a href=\"https://www.manning.com/books/build-a-large-language-model-from-scratch\">https://www.manning.com/books/build-a-large-language-model-from-scratch</a> by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
   "metadata": {
    "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
   },
   "source": [
    "# Chapter 5: 在未标记数据上进行预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92b989e9-da36-4159-b212-799184764dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.1\n",
      "numpy version: 2.2.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \"numpy\", \"tiktoken\", \"torch\"]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
   "metadata": {},
   "source": [
    "- 在本章中，我们将实现训练循环及基本模型评估代码，以预训练一个LLM\n",
    "- 本章结尾处，我们还将加载OpenAI提供的公开可用的预训练权重并将其导入到我们的模型中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
   "metadata": {},
   "source": [
    "<img src=\"images/img-1.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214765-7a73-42d5-95e9-302154b29db9",
   "metadata": {},
   "source": [
    "- 本章所涵盖的主题如下图所示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
   "metadata": {},
   "source": [
    "<img src=\"images/img-2.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
   "metadata": {
    "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
   },
   "source": [
    "## 5.1 评估文本生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
   "metadata": {},
   "source": [
    "- 我们首先简要回顾一下使用上一章中的代码初始化 GPT 模型\n",
    "- 然后，我们讨论 LLM 的基本评估指标\n",
    "- 最后，在本节中，我们将这些评估指标应用于训练和验证数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
   "metadata": {
    "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
   },
   "source": [
    "### 5.1.1 使用 GPT 生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
   "metadata": {},
   "source": [
    "- 我们使用上一章中的代码初始化 GPT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86000d74-624a-48f0-86da-f41926cb9e04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86000d74-624a-48f0-86da-f41926cb9e04",
    "outputId": "ad482cfd-5a62-4f0d-e1e0-008d6457f512"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"ctx_len\": 256,       # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,       # Embedding dimension\n",
    "    \"n_heads\": 12,        # Number of attention heads\n",
    "    \"n_layers\": 12,       # Number of layers\n",
    "    \"drop_rate\": 0.1,     # Dropout rate\n",
    "    \"qkv_bias\": False     # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
   "metadata": {},
   "source": [
    "- 我们在上面使用0.1的dropout，但现在的llm训练中通常没有dropout\n",
    "- 现在的llm也不会在查询，键和值矩阵的`nn.Linear`层中使用偏差向量 (与早期的GPT模型不同)，这是通过设置`“qkv_bias”: False`来实现的\n",
    "- 我们只用256个token的上下文长度 (`ctx_len`)，以减少训练模型的计算资源需求，而原始的1.24亿参数GPT-2模型使用1024个token\n",
    "  - 这是为了让更多的读者能够在他们的笔记本电脑上执行代码示例\n",
    "  - 但是，请随意增加`ctx_len`到1024token (这不需要任何代码更改)\n",
    "  - 之后我们还将从预训练的权重加载具有`ctx_len = 1024`的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
   "metadata": {},
   "source": [
    "- 接下来，我们使用上一章中的`generate_text_simple`函数来生成文本。\n",
    "- 此外，我们定义了两个函数`text_to_token_ids`和`token_ids_to_text`，用于在本章中进行标记和文本表示之间的转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
   "metadata": {},
   "source": [
    "<img src=\"images/img-3.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token ids are: \n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "\n",
      "input embbeding's shape is: torch.Size([1, 4, 768])\n",
      "\n",
      "input embbeding are: \n",
      "tensor([[[ 1.6146,  2.1622,  1.2770,  ...,  0.0111, -1.1353, -0.2450],\n",
      "         [-1.6020, -1.3996,  0.4308,  ...,  0.0913, -0.0614, -0.0538],\n",
      "         [ 0.7265,  1.0869, -0.2251,  ..., -0.0742,  0.1081,  0.9774],\n",
      "         [-0.4047, -0.0914, -1.5747,  ..., -1.5130,  0.4232,  0.5841]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "Output token ids' shape: torch.Size([1, 14])\n",
      "Output token ids are: \n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308,  3398, 13174, 43071]])\n",
      "\n",
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # 增加batch维度\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # 去掉batch维度\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# token_ids = generate_text_simple(\n",
    "#     model=model,\n",
    "#     idx=text_to_token_ids(start_context, tokenizer),\n",
    "#     max_new_tokens=10,\n",
    "#     context_size=GPT_CONFIG_124M[\"ctx_len\"]\n",
    "# )\n",
    "start_ids = text_to_token_ids(text=start_context, tokenizer=tokenizer)\n",
    "print(f\"Input token ids are: \\n{start_ids}\\n\")\n",
    "\n",
    "# 回顾一下嵌入层的输出：\n",
    "input_embbed = model.tok_emb(start_ids)\n",
    "print(f\"input embbeding's shape is: {input_embbed.shape}\\n\")\n",
    "print(f\"input embbeding are: \\n{input_embbed}\\n\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=start_ids,\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"ctx_len\"]\n",
    ")\n",
    "print(f\"Output token ids' shape: {token_ids.shape}\")\n",
    "print(f\"Output token ids are: \\n{token_ids}\\n\")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
   "metadata": {},
   "source": [
    "- 如上所述，模型未能生成好的文本，因为它尚未经过训练。\n",
    "- 我们如何以数值形式衡量或捕捉“好的文本”，以便在训练过程中进行跟踪？\n",
    "- 下一小节将介绍用于计算生成输出的损失指标的度量标准，我们可以使用这些度量标准来衡量训练进度。\n",
    "- 在后续关于微调大型语言模型（LLMs）的章节中，也将介绍其他衡量模型质量的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
   "metadata": {
    "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
   },
   "source": [
    "### 5.1.2 计算文本生成损失：交叉熵和困惑度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
   "metadata": {},
   "source": [
    "- 假设我们有一个`inputs`张量，包含了2个训练样本（行）的标记ID。\n",
    "- 对应于`inputs`，`targets`包含了我们希望模型生成的期望标记ID。\n",
    "- 请注意，`targets`是`inputs`向右移动了一个位置，正如第2章中实现数据加载器时所解释的那样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
    "outputId": "8d6fa0ff-7b37-4634-c3f0-2c050cbe81f0"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [588,  428,  11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
   "metadata": {},
   "source": [
    "- 将`inputs`输入模型后，我们获得了包含3个标记的2个输入样本的logits向量。\n",
    "- 每个标记都是一个50,257维的向量，对应于词汇表的大小。\n",
    "- 应用softmax函数，我们可以将logits张量转换为一个相同维度的张量，其中包含概率分数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits's shape: torch.Size([2, 3, 50257])\n",
      "logits: \n",
      "tensor([[[ 0.1113, -0.1057, -0.3666,  ...,  0.2843, -0.8824,  0.1074],\n",
      "         [-0.6109, -0.5167, -0.7613,  ...,  0.5450, -1.0319, -0.2175],\n",
      "         [ 0.5707, -0.6459, -0.0701,  ...,  0.7419, -0.1806, -0.2217]],\n",
      "\n",
      "        [[-0.2968,  0.1949, -0.1649,  ..., -0.4867,  0.7218, -0.1714],\n",
      "         [-0.8375,  0.0612, -0.4641,  ...,  0.2327, -0.3889, -0.0770],\n",
      "         [ 0.5614,  0.6919,  0.8915,  ..., -0.9472,  1.2411, -0.2056]]])\n",
      "\n",
      "probas's shape: torch.Size([2, 3, 50257])\n",
      "probas: \n",
      "tensor([[[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05,\n",
      "          6.9776e-06, 1.8776e-05],\n",
      "         [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05,\n",
      "          6.0103e-06, 1.3571e-05],\n",
      "         [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05,\n",
      "          1.4094e-05, 1.3526e-05]],\n",
      "\n",
      "        [[1.2561e-05, 2.0537e-05, 1.4332e-05,  ..., 1.0389e-05,\n",
      "          3.4784e-05, 1.4239e-05],\n",
      "         [7.2731e-06, 1.7864e-05, 1.0565e-05,  ..., 2.1207e-05,\n",
      "          1.1390e-05, 1.5559e-05],\n",
      "         [2.9496e-05, 3.3605e-05, 4.1029e-05,  ..., 6.5249e-06,\n",
      "          5.8203e-05, 1.3698e-05]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "print(f\"logits's shape: {logits.shape}\")\n",
    "print(f\"logits: \\n{logits}\\n\")\n",
    "probas = torch.softmax(logits, dim=-1) # 词表中每个标记的预测概率\n",
    "print(f\"probas's shape: {probas.shape}\") # Shape: (batch_size, num_tokens, vocab_size)\n",
    "print(f\"probas: \\n{probas}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
   "metadata": {},
   "source": [
    "- 下图为了说明目的使用了一个非常小的词汇表，概述了我们如何将概率分数转换回文本，这一点我们在上一章的末尾进行了讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480efd-d419-4954-9ecc-2876055334bd",
   "metadata": {},
   "source": [
    "- 正如在前一章中讨论的，我们可以应用`argmax`函数将概率分数转换为预测的标记ID。\n",
    "- 上文提到的softmax函数为每个标记生成了一个50,257维的向量；`argmax`函数返回这个向量中最高概率分数的位置，即给定标记的下一个预测标记ID。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
   "metadata": {},
   "source": [
    "- 由于我们有2个输入批次，每个批次包含3个标记，因此我们获得了2个3维的预测标记ID："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
    "outputId": "ed17da47-c3e7-4775-fd00-4ec5bcda3db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids' shape: torch.Size([2, 3, 1])\n",
      "\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "# 执行了argmax之后，shape由 (2, 3, 50257) 变成 (2, 3, 1)\n",
    "print(f\"token_ids' shape: {token_ids.shape}\\n\")\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4072c-21ed-4df7-8721-dd2535362573",
   "metadata": {},
   "source": [
    "- 如果我们解码这些标记，我们会发现它们与我们希望模型预测的标记，即目标标记，相当不同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
   "metadata": {},
   "source": [
    "- 那是因为模型还没有被训练。\n",
    "- 为了训练模型，我们需要知道它离正确预测（目标）有多远。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7251bf5-a079-4782-901d-68c9225d3157",
   "metadata": {},
   "source": [
    "- 对应于目标索引的标记概率如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
    "outputId": "41c946a2-c458-433e-a53d-5e7e89d9dddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets[0]: tensor([3626, 6100,  345])\n",
      "Batch 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Batch 2: tensor([3.9835e-05, 1.6783e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "batch_idx = 0\n",
    "print(f\"targets[{batch_idx}]: {targets[batch_idx]}\")\n",
    "target_probas_1 = probas[batch_idx, [0, 1, 2], targets[batch_idx]]\n",
    "print(\"Batch 1:\", target_probas_1) # 等价于：print(probas[batch_idx][0][3626], probas[batch_idx][1][6100], probas[batch_idx][2][345])\n",
    "\n",
    "batch_idx = 1\n",
    "target_probas_2 = probas[1, [0, 1, 2], targets[1]]\n",
    "print(\"Batch 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
   "metadata": {},
   "source": [
    "- 我们希望最大化所有这些值，使它们接近1的概率。\n",
    "- 在数学优化中，最大化概率分数的对数比分数值本身更容易；这超出了本书的范围，但我在这里录制了一个更详细的讲座：[L8.2 逻辑回归损失函数](https://www.youtube.com/watch?v=GxJe0DZvydM)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
    "outputId": "1bf18e79-1246-4eab-efd8-12b328c78678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -10.1308, -10.9951, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 计算所有标记的预测概率的对数值\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4261441-a511-4633-9c4c-67998af31b84",
   "metadata": {},
   "source": [
    "- 接下来，我们计算平均对数概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b003797-161b-4d98-81dc-e68320e09fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b003797-161b-4d98-81dc-e68320e09fec",
    "outputId": "a447fe9c-7e27-40ed-f1fb-51210e3f7cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7722)\n"
     ]
    }
   ],
   "source": [
    "# 对所有标记的概率对数值求均值\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
   "metadata": {},
   "source": [
    "- 目标是通过优化模型权重，使得这个平均对数概率尽可能大。\n",
    "- 由于对数函数的特性，最大可能的值是0，而我们目前远离0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
   "metadata": {},
   "source": [
    "- 在深度学习中，我们通常不是最大化平均对数概率，而是遵循标准惯例来最小化平均对数概率的*负值*；在我们的例子中，不是最大化-10.7722使其接近0，在深度学习中，我们会最小化10.7722使其接近0。\n",
    "- 负-10.7722的值，即10.7722，在深度学习中也被称为交叉熵损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7722)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
   "metadata": {},
   "source": [
    "- PyTorch 已经实现了一个 `cross_entropy` 函数，该函数执行了前面的步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
   "metadata": {},
   "source": [
    "- 在我们应用交叉熵函数之前，让我们先检查一下logits和targets的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
    "outputId": "43fd802a-8136-4b35-df0d-f61a5d4cb561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits向量的形状 (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# 目标向量的形状 (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
   "metadata": {},
   "source": [
    "- 对于PyTorch中的`entropy_loss`函数，我们希望通过在批次(batch)维度上合并它们来展平(flatten)这些张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
    "outputId": "0b2b778b-02fb-43b2-c879-adc59055a7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921a57f-3a79-473e-a863-6d63b495010f",
   "metadata": {},
   "source": [
    "- 请注意，目标（targets）是标记ID，它们也代表了我们希望在logits张量中最大化的索引位置。\n",
    "- PyTorch中的`cross_entropy`函数会自动地将softmax和对数概率计算应用到这些要最大化标记索引的logits上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
    "outputId": "c0be634a-2c65-4ff7-a73f-1bfc2e406ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7722)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
   "metadata": {},
   "source": [
    "- 一个 与交叉熵损失相关的概念是大型语言模型（LLM）的困惑度。\n",
    "- 困惑度简单地说就是交叉熵损失的指数函数计算结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "168952a1-b964-4aa7-8e49-966fa26add54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168952a1-b964-4aa7-8e49-966fa26add54",
    "outputId": "a0a692c1-6412-4068-8aa5-8858548141eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47678.8672)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
   "metadata": {},
   "source": [
    "- 困惑度通常被认为更具可解释性，因为它可以被理解为模型在每一步中对下一标记所不确定的词表大小（在上面的例子中，这将是47,678个单词或标记）。\n",
    "- 换句话说，困惑度提供了一种衡量模型预测的概率分布与数据集中单词实际分布匹配程度的方法。\n",
    "- 与损失类似，较低的困惑度表明模型预测更接近实际分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
   "metadata": {
    "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
   },
   "source": [
    "### 5.1.3 计算训练集和验证集损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
   "metadata": {},
   "source": [
    "- 我们使用一个相对较小的数据集来训练大型语言模型（LLM）（实际上，只有一个短篇故事）。\n",
    "  - 原因包括：\n",
    "    - 你可以在没有合适GPU的笔记本电脑上在几分钟内运行代码示例。\n",
    "    - 训练完成得相对较快（几分钟而不是几周），这对我们的教育目的来说很好。\n",
    "    - 我们使用的是公有领域的文本，可以包含在这个GitHub仓库中而不会违反任何使用权或增加仓库大小。\n",
    "\n",
    "- 例如，Llama 2 7B在A100 GPU上需要184,320小时的训练时间才能在2万亿个标记上完成训练。\n",
    "  - 在撰写本文时，AWS上8xA100云服务器的每小时成本大约为30美元。\n",
    "  - 因此，通过一个粗略的计算，训练这个LLM的成本将是 184,320 / 8 * 30美元 = 69万美元。\n",
    "\n",
    "- 下面，我们将使用第2章中使用过的相同数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://github.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379330f1-80f4-4e34-8724-41d892b04cee",
   "metadata": {},
   "source": [
    "- 通过打印前100个和后100个单词来快速检查文本是否正确加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6kgJbe4ehI4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6kgJbe4ehI4q",
    "outputId": "9ff31e88-ee37-47e9-ee64-da6eb552f46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "j2XPde_ThM_e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j2XPde_ThM_e",
    "outputId": "a900c1b9-9a87-4078-968b-a5721deda5cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
    "outputId": "c2a25334-21ca-486e-8226-0296e5fc6486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_char = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_char)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
   "metadata": {},
   "source": [
    "- 虽然只有5,145个标记，对于训练一个大型语言模型（LLM）来说，这段文本非常短，但再次强调，这是出于教育目的（我们稍后还会加载预训练的权重）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
   "metadata": {},
   "source": [
    "- 接下来，我们将数据集划分为训练集和验证集，并使用第2章中的数据加载器为大型语言模型（LLM）训练准备批次数据。\n",
    "- 为了可视化目的，下面的图表假设`max_length=6`，但对于训练加载器，我们将`max_length`设置为LLM支持的上下文长度。\n",
    "- 下面的图表仅显示输入标记以简化表示。\n",
    "  - 由于我们训练LLM来预测文本中的下一个单词，目标标记看起来与这些输入标记相同，只是目标标记向右移动了一个位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0959c855-f860-4358-8b98-bc654f047578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# 训练集/验证集数据比\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    stride=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    stride=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合理性检查：为了确保训练集和验证集中数据量大于模型的上下文窗口，避免出现训练/验证错误\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"ctx_len\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['ctx_len']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"ctx_len\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['ctx_len']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
   "metadata": {},
   "source": [
    "- 我们使用相对较小的批次大小来减少计算资源的需求，并且因为数据集本身起初就非常小。\n",
    "- 例如，Llama 2 7B就是使用1024的批次大小进行训练的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
   "metadata": {},
   "source": [
    "- 一个可选的检查，以确认数据是否已正确加载："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
   "metadata": {},
   "source": [
    "- 另一个可选的检查，以确认标记大小是否在预期的范围内："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb860488-5453-41d7-9870-23b723f742a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb860488-5453-41d7-9870-23b723f742a0",
    "outputId": "96b9451a-9557-4126-d1c8-51610a1995ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel() # 使用numel()函数统计一个batch中的token数量\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
   "metadata": {},
   "source": [
    "- 接下来，我们实现一个实用工具函数来计算给定批次的交叉熵损失。\n",
    "- 此外，我们实现了第二个实用工具函数，用于计算数据加载器中用户指定数量批次的总损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
   "metadata": {
    "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "    logits = logits.flatten(0, 1)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None): # num_batches为计算损失的批次范围\n",
    "    total_loss = 0.\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 取num_batches和len(data_loader)两者较小值以匹配data_loader中的总批次数量\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
   "metadata": {},
   "source": [
    "- 如果你拥有一台装有支持CUDA的GPU的计算机，大型语言模型（LLM）将在GPU上进行训练，无需对代码做任何更改。\n",
    "- 通过`device`设置，我们确保数据被加载到与LLM模型相同的设备上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m model.to(device) \u001b[38;5;66;03m# 对于nn.Module类的模型，不需要执行model = model.to(device)这样的赋值操作。\u001b[39;00m\n\u001b[32m      5\u001b[39m torch.manual_seed(\u001b[32m123\u001b[39m) \u001b[38;5;66;03m# 出于代码结果的可复现性的考虑，显式地设定manual_seed\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m train_loss = calc_loss_loader(\u001b[43mtrain_loader\u001b[49m, model, device)\n\u001b[32m      7\u001b[39m val_loss = calc_loss_loader(val_loader, model, device)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining loss:\u001b[39m\u001b[33m\"\u001b[39m, train_loss)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # 对于nn.Module类的模型，不需要执行model = model.to(device)这样的赋值操作。\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # 出于代码结果的可复现性的考虑，显式地设定manual_seed\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-1.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
   "metadata": {
    "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
   },
   "source": [
    "## 5.2 训练一个大型语言模型（LLM）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
   "metadata": {},
   "source": [
    "- 在本节中，我们最终实现了训练大型语言模型（LLM）的代码。\n",
    "- 我们专注于一个简单的训练函数（如果你对使用更先进的技术增强这个训练函数感兴趣，例如学习率预热、余弦退火和梯度裁剪，请参考[Appendix D](../../appendix-D/03_main-chapter-code))\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "Mtp4gY0ZO-qq",
   "metadata": {
    "id": "Mtp4gY0ZO-qq"
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context):\n",
    "    # 初始化列表以跟踪损失和已观察到的token\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # 主要的训练步骤\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 将模型设置为训练模式\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # 每个epoch开始之前重新设置梯度\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # 计算损失梯度\n",
    "            optimizer.step() # 利用损失梯度更新模型参数\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # 可选的验证评估步骤\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 在每个epoch完成后打印一个生成的文本示例\n",
    "        generate_and_print_sample(\n",
    "            model, train_loader.dataset.tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # 简洁的打印格式\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
   "metadata": {},
   "source": [
    "- 现在，让我们使用上面定义的训练函数来训练大型语言模型（LLM）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3422000b-7aa2-485b-92df-99372cd22311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3422000b-7aa2-485b-92df-99372cd22311",
    "outputId": "0e046603-908d-4093-8ae5-ef2f632639fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.558, Val loss 9.856\n",
      "Ep 1 (Step 000005): Train loss 7.651, Val loss 8.051\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.421, Val loss 6.812\n",
      "Ep 2 (Step 000015): Train loss 5.913, Val loss 6.559\n",
      "Every effort moves you, and, and,, and,,,,, and, and,,,, and,,,, and, and,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.680, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 5.557, Val loss 6.602\n",
      "Every effort moves you, and, and the picture.                             \", and, and the, and the, and, and,\n",
      "Ep 4 (Step 000030): Train loss 5.204, Val loss 6.508\n",
      "Ep 4 (Step 000035): Train loss 4.865, Val loss 6.420\n",
      "Every effort moves you, and I had a a a--I to the picture. \"I. I had the picture. \"I had the picture. I had the the picture. I had the the picture. \"I had the picture. \"\n",
      "Ep 5 (Step 000040): Train loss 4.332, Val loss 6.328\n",
      "Every effort moves you, I was a and I was a little to the picture.                                     \n",
      "Ep 6 (Step 000045): Train loss 4.295, Val loss 6.221\n",
      "Ep 6 (Step 000050): Train loss 3.268, Val loss 6.184\n",
      "Every effort moves you know to see the end of the Riv I felt--the a little of the last: \"                               \n",
      "Ep 7 (Step 000055): Train loss 2.880, Val loss 6.129\n",
      "Ep 7 (Step 000060): Train loss 2.820, Val loss 6.194\n",
      "Every effort moves you know the fact of a little a--I was his painting.                                     \n",
      "Ep 8 (Step 000065): Train loss 2.260, Val loss 6.236\n",
      "Ep 8 (Step 000070): Train loss 1.754, Val loss 6.260\n",
      "Every effort moves you know,\" was one of the picture for nothing--I turned Mrs.                                    \n",
      "Ep 9 (Step 000075): Train loss 1.447, Val loss 6.319\n",
      "Ep 9 (Step 000080): Train loss 1.120, Val loss 6.310\n",
      "Every effort moves you?\"               \"I looked--and me.\"         He placed them at my elbow and I looked up his pictures--because he's I had\n",
      "Ep 10 (Step 000085): Train loss 0.762, Val loss 6.372\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0WSRu2i0iHJE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0WSRu2i0iHJE",
    "outputId": "9d36c61b-517d-4f07-a7e8-4563aff78b11"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # 绘制随着训练进行（epoch值增大）训练集损失和验证集损失的变化情况\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "\n",
    "    # 创建第二个x轴用于显示可观察的tokens\n",
    "    ax2 = ax1.twiny()  # 创建一个共享相同y轴的第二个x轴\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 用于对齐刻度的不可见图表\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # 调整布局以节省空间\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
   "metadata": {},
   "source": [
    "- 从上面的结果来看，我们可以看到模型开始生成无法理解的单词串，而到了后期，它能够产生语法上或多或少正确的句子。\n",
    "- 然而，根据训练集和验证集的损失情况，我们可以看到模型开始过拟合。\n",
    "- 如果我们检查它在训练结束时写的几段文本，我们会发现自己它们与训练集中的内容几乎一字不差——它只是简单地记住了训练数据。\n",
    "- 稍后，我们将讨论一些解码策略，可以在一定程度上减轻这种记忆现象。\n",
    "- 请注意，这里的过拟合是因为我们有一个非常非常小的训练集，而且我们多次迭代它。\n",
    "  - 这里的大型语言模型训练主要是出于教育目的；我们主要想看到模型能够学习产生连贯的文本。\n",
    "  - 我们不会花费数周或数月的时间在昂贵的硬件上训练这个模型，我们将在后续加载预训练的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-2.webp\" width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de713235-1561-467f-bf63-bf11ade383f0",
   "metadata": {},
   "source": [
    "**如果您对使用更先进的技术来增强这个训练函数感兴趣，例如学习率预热、余弦退火和梯度裁剪，请参考[附录D](../../appendix-D/03_main-chapter-code)。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
   "metadata": {},
   "source": [
    "**如果您对更大的训练数据集和更长时间的训练感兴趣，请查看 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
   "metadata": {
    "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
   },
   "source": [
    "## 5.3 解码策略以控制随机性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
   "metadata": {},
   "source": [
    "- 使用相对较小的大型语言模型（如我们上面训练的GPT模型），推理过程相对廉价，因此如果您在上面使用GPU进行了训练，那么在推理时就不需要使用GPU。\n",
    "- 使用我们之前在简单训练函数中使用的`generate_text_simple`函数（来自上一章），我们可以一次生成一个单词（或标记）的新文本。\n",
    "- 如5.1.2节所解释的，下一个生成的标记是词汇表中所有标记中对应最大概率分数的标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"ctx_len\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
   "metadata": {},
   "source": [
    "- 即使我们多次执行上面的`generate_text_simple`函数，大型语言模型（LLM）始终会生成相同的输出。\n",
    "- 现在我们引入两个概念，所谓的解码策略，来修改`generate_text_simple`：*温度缩放*和*top-k*采样。\n",
    "- 这将允许模型控制生成文本的随机性和多样性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
   "metadata": {},
   "source": [
    "### 5.3.1 温度缩放"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
   "metadata": {},
   "source": [
    "- 之前，我们总是使用`torch.argmax`采样最大概率的标记作为下一个标记。\n",
    "- 为了增加多样性，我们可以使用`torch.multinomial(probs, num_samples=1)`从概率分布中采样下一个标记。\n",
    "- 在这里，每个索引被选中的机会与其在输入张量中的概率相对应。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
   "metadata": {},
   "source": [
    "- 这里是一个关于生成下一个标记的小回顾，假设一个非常小的词汇表，仅用于说明目的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# 假设input是 \"every effort moves you\", 模型返回的logits值为下面tensor中的数值:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# 下一个标记:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)] # 使用torch.multinomial函数从probas中进行了1000次采样\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample)) # 使用torch.bitcount函数统计每个token的采样数量\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
   "metadata": {},
   "source": [
    "- 我们不是通过`torch.argmax`来确定最可能的标记，而是使用`torch.multinomial(probas, num_samples=1)`从softmax分布中采样来确定最可能的标记。\n",
    "- 为了说明，让我们看看当我们使用原始的softmax概率采样1000次下一个标记时会发生什么："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
   "metadata": {},
   "source": [
    "- 我们可以通过一个称为温度缩放的概念来控制分布和选择过程。\n",
    "- “温度缩放”只是将logits除以一个大于0的数字的高级说法。\n",
    "- 大于1的温度值将在应用softmax后导致更均匀分布的标记概率。\n",
    "- 小于1的温度值将在应用softmax后导致更自信（更尖锐或更高峰）的分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, T in enumerate(temperatures):\n",
    "    # 条形图的绘制，ax.bar()函数里面的参数分别为条形的x轴位置、高度、宽度、图例标签\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
   "metadata": {},
   "source": [
    "- 我们可以看到，通过温度0.1进行重新缩放会得到一个更尖锐的分布，接近于`torch.argmax`，以至于最可能的单词几乎总是被选中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
   "metadata": {},
   "source": [
    "- 通过`temperature=5`重新缩放的概更加均匀："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
   "metadata": {},
   "source": [
    "- 假设大型语言模型（LLM）的输入是“every effort moves you”，使用上述方法有时会产生无意义的文本，例如“every effort moves you pizza”，这种情况发生的频率是3.2%（在1000次中有32次）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k采样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
   "metadata": {},
   "source": [
    "- 为了能够使用更高的温度来增加输出的多样性，并降低无意义句子出现的概率，我们可以将采样的标记限制在最可能的前k个标记中："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
   "metadata": {},
   "source": [
    "- 在代码中，我们可以如下实现这一点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
   "metadata": {},
   "source": [
    "### 5.3.3 修改文本生成函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34770423-473d-46f6-a5fa-6b2979564d26",
   "metadata": {},
   "source": [
    "- 前两个小节介绍了温度采样和top-k采样。\n",
    "- 让我们使用这两个概念来修改我们之前用于通过大型语言模型（LLM）生成文本的`generate_simple`函数，创建一个新的`generate`函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature, top_k=None):\n",
    "\n",
    "    # 循环与之前相同：获取logits，并仅关注最后一步。\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 使用top_k采样对logits值进行过滤\n",
    "        if top_k is not None:\n",
    "            # 仅保留top_k的值\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        # 使用温度缩放\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # 使用softmax函数得到概率\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # 从概率分布中采样\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # 否则和之前的generate_simple函数中的处理相同，使用argmax函数取得概率最大的token\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        # 和之前相同的序列拼接处理\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\",\" was down surprise. It is to face watching me by his painting him back to my work\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=20,\n",
    "    context_size=GPT_CONFIG_124M[\"ctx_len\"],\n",
    "    top_k=10,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
   "metadata": {},
   "source": [
    "## 5.4 在PyTorch中加载和保存模型权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc52676-f026-4566-a226-2a90269f9d53",
   "metadata": {},
   "source": [
    "- 训练大型语言模型（LLM）需要昂贵的计算资源，因此能够保存和加载LLM权重至关重要。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-3.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
   "metadata": {},
   "source": [
    "- PyTorch推荐的方式是保存模型权重，即所谓的`state_dict`，通过应用`torch.save`函数到`.state_dict()`方法来实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
   "metadata": {},
   "source": [
    "- 然后我们可以按照以下方式将模型权重加载到一个新的`GPTModel`模型实例中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
   "metadata": {},
   "source": [
    "- 通常的做法是使用自适应优化器（如Adam或AdamW）而不是常规的SGD来训练大型语言模型（LLM）\n",
    "- 这些自适应优化器会为每个模型权重存储额外的参数，因此如果我们计划稍后继续预训练，保存它们也是有意义的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a0c7295-c822-43bf-9286-c45abc542868",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194350e-0409-4a63-8ffd-d3a896509032",
   "metadata": {},
   "source": [
    "## 5.5 从Open AI加载预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
   "metadata": {},
   "source": [
    "- 之前，我们仅出于教育目的使用一本非常小的短篇小说书训练了一个小型的GPT-2模型。\n",
    "- 感兴趣的读者还可以在[../03_bonus_pretraining_on_gutenberg](03_bonus_pretraining_on_gutenberg)中找到在完整的古登堡计划书库上进行更长时间预训练的信息。\n",
    "- 幸运的是，我们不需要花费数万到数十万美元在大型预训练语料库上预训练模型，而是可以直接加载由OpenAI提供的预训练权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
   "metadata": {},
   "source": [
    "- 从Hugging Face Hub加载权重的方法，请参见[../02_alternative_weight_loading](../02_alternative_weight_loading)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cab892-a165-4f43-9601-f517bc212ab6",
   "metadata": {},
   "source": [
    "- 首先，一些模板代码用于从OpenAI下载文件并将权重加载到Python中。\n",
    "- 由于OpenAI使用了[TensorFlow](https://www.tensorflow.org/)，我们将不得不安装并使用TensorFlow来加载权重；[tqdm](https://github.com/tqdm/tqdm) 是一个进度条库。\n",
    "- 取消注释并运行下一个单元格以安装所需的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有关的函数导入\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc",
   "metadata": {},
   "source": [
    "- 然后我们可以按照以下方式下载具有1.24亿参数的模型权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [23:56<00:00, 347kiB/s]     \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 4.67MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 304kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 235kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "hparams, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b20f0",
   "metadata": {},
   "source": [
    "note: 如果出现报错：requests.exceptions.SSLError: Max retries exceeded weith url \n",
    "更改urllib3的版本\n",
    "`pip install urllib3==1.25.11`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e100c-294e-4afc-a70a-2f398ac4c104",
   "metadata": {},
   "source": [
    "- 另外，\"355M\"、\"774M\" 和 \"1558M\" 也是支持的 `model_size` 参数。\n",
    "- 这些不同大小的模型之间的差异在下面的图表中进行了总结："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f19d32-5aae-4176-9f86-f391672c8f0d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-sizes.webp?timestamp=123\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41",
   "metadata": {},
   "source": [
    "- 上面，我们将124M GPT-2模型权重加载到了Python中，但我们还需要将它们转移到我们的`GPTModel`实例中。\n",
    "- 首先，我们初始化一个新的GPTModel实例。\n",
    "- 请注意，原始的GPT模型在多头注意力模块的查询、键和值矩阵的线性层中使用了带偏置向量的初始化，这是不必要的，也不推荐；然而，为了能够正确加载权重，我们也必须在我们的实现中通过设置`qkv_bias`为`True`来启用这些。\n",
    "- 我们还使用了原始GPT-2模型使用的`1024`上下文窗口长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fef90dd-0654-4667-844f-08e28339ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型配置参数定义在一个字典中\n",
    "model_configs = {\n",
    "    \"gpt2-small\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# 复制基础配置，并使用特定的模型设置进行更新\n",
    "model_name = \"gpt2-small\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"ctx_len\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f29ac-8342-4b3d-a57d-9b0166ced314",
   "metadata": {},
   "source": [
    "- 接下来需要将OpenAI的权重分配给我们的`GPTModel`实例中相应的权重张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a92229-c002-49a6-8cfb-248297ad8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    # Weight tying\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "    \n",
    "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "    \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    \n",
    "        gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "        gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "        gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7472cb-54dc-4311-96d8-b2694f885cee",
   "metadata": {},
   "source": [
    "- 如果模型加载正确，我们可以使用它结合我们之前的`generate`函数来生成新文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"ctx_len\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
   "metadata": {},
   "source": [
    "- 我们知道模型权重加载正确，因为模型能够生成连贯的文本；如果我们犯了哪怕很小的错误，模型也无法做到这一点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
   "metadata": {},
   "source": [
    "- 有关从Hugging Face Hub加载权重的替代方法，请参考[../02_alternative_weight_loading](../02_alternative_weight_loading)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
   "metadata": {},
   "source": [
    "## 总结和要点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
   "metadata": {},
   "source": [
    "- 查看包含独立训练脚本的[gpt_train.py](gpt_train.py)文件。\n",
    "- [gpt_generate.py](gpt_generate.py)文件从OpenAI加载预训练权重，并根据提示生成文本。\n",
    "- 你可以在[exercise-solutions.ipynb](exercise-solutions.ipynb)中找到练习题的解答。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
